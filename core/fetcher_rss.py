import urllib.parse
import feedparser
from datetime import datetime, timezone, timedelta
from openai import OpenAI

# â± í•œêµ­ ì‹œê°„ëŒ€ ê¸°ì¤€ (í‘œì‹œìš©)
KST = timezone(timedelta(hours=9))
now = datetime.now(KST)

# ì „ì—­ ë³€ìˆ˜ë¡œ API í‚¤ ì €ì¥
api_key = None

def set_api_key(key):
    global api_key
    api_key = key

def translate_to_english(korean_keyword: str) -> str:
    """
    GPTë¥¼ ì‚¬ìš©í•´ í•œêµ­ì–´ í‚¤ì›Œë“œë¥¼ ì˜ì–´ë¡œ ë²ˆì—­ (í•œë‘ ë‹¨ì–´, ì„¤ëª… ì—†ì´)
    """
    if not api_key:
        print("âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return korean_keyword

    client = OpenAI(api_key=api_key)

    prompt = f"Translate the Korean phrase to a concise English keyword (1~2 words, no explanation): {korean_keyword}"
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are a helpful assistant that returns only short English keywords."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=10,
            temperature=0.3,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"âŒ ë²ˆì—­ ì‹¤íŒ¨: {e}")
        return korean_keyword

def parse_date(entry):
    date_str = entry.get("published") or entry.get("updated") or entry.get("dc_date")
    if not date_str:
        print("âŒ ë‚ ì§œ ì •ë³´ ì—†ìŒ:", entry.get("title", "ì œëª© ì—†ìŒ"))
        return None

    try:
        return datetime.strptime(date_str, "%a, %d %b %Y %H:%M:%S %Z").astimezone(KST)
    except ValueError:
        try:
            return datetime.fromisoformat(date_str).astimezone(KST)
        except ValueError:
            print("âŒ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨:", date_str)
            return None

def get_rss_news(keyword: str):
    """
    Google News RSS (êµ­ë‚´ + êµ­ì™¸)ì—ì„œ ìˆ˜ì§‘
    í•œêµ­ì–´ í‚¤ì›Œë“œëŠ” ìë™ ë²ˆì—­í•˜ì—¬ êµ­ì™¸ ê²€ìƒ‰ì— ì‚¬ìš©
    """
    encoded_kr = urllib.parse.quote(keyword)

    if any('\uac00' <= ch <= '\ud7a3' for ch in keyword):
        translated = translate_to_english(keyword)
    else:
        translated = keyword
    encoded_en = urllib.parse.quote(translated)

    rss_urls = {
        "êµ­ë‚´": f"https://news.google.com/rss/search?hl=ko&gl=KR&ceid=KR:ko&q={encoded_kr}+when:24h",
        "êµ­ì™¸": f"https://news.google.com/rss/search?hl=en&gl=US&ceid=US:en&q={encoded_en}+when:24h"
    }

    all_articles = []
    idx = 1

    for region, url in rss_urls.items():
        print(f"\nğŸŒ {region} RSS URL: {url}")
        feed = feedparser.parse(url)
        print(f"ğŸ“¦ ìˆ˜ì§‘ëœ ê¸°ì‚¬ ìˆ˜: {len(feed.entries)}")

        for entry in feed.entries:
            pub_date = parse_date(entry)
            pub_date_str = pub_date.strftime("%Y-%m-%d %H:%M:%S") if pub_date else "ë‚ ì§œ ì—†ìŒ"
            title = entry.get("title", "ì œëª© ì—†ìŒ").strip()
            link = entry.get("link", "ë§í¬ ì—†ìŒ").strip()
            description = entry.get("description", "ìš”ì•½ ì—†ìŒ").strip()

            # print(f"âœ… [{idx}] {title} ({region})")
            # print(f"    ğŸ“… {pub_date_str}")
            # print(f"    ğŸ”— {link}")
            # print(f"    ğŸ“ ìš”ì•½: {description}\n")

            all_articles.append([title, link, description, pub_date_str])
            idx += 1

    print(encoded_en)
    return all_articles

# í…ŒìŠ¤íŠ¸ìš© ì‹¤í–‰
if __name__ == "__main__":
    get_rss_news("ë””ì§€í„¸ í—¬ìŠ¤ì¼€ì–´")
